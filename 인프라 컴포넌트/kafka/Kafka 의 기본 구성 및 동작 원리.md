#kafka #spring 

📌 Kafka 는 Cluster -> Broker -> Topic -> Partition -> Segment 로 구성되어 있다.

![사진](../../images/kafka1.png)

___ 

# Kafka 용어 설명

### ✅ 클러스터(Cluster)

- 여러 대의 서버(브로커)로 구성된 Kafka 시스템이다.
- 메시지의 저장, 처리, 전달을 담당한다.
- 대량의 데이터를 처리하고 생산자(producer)와 소비자(consumer)에게 메시지 서비스를 제공한다.

![사진](../../images/kafka4.png)

### ✅ 브로커(Broker)

- Kafka 시스템을 구성하는 개별 서버이다.
	- 컨테이너의 개수와 동일한 개념이다(서버 그 자체임 브로커가)
- 외부 서버가 아닌 Kafka 서버 프로세스로 실행된다.
- 각 브로커는 Kafka Topic의 하나 이상의 Partition이 제공된다.
- 생산자로부터 데이터를 받고 소비자에게 데이터를 전달한다.
- 데이터의 안정성을 위해 파티션을 여러 브로커에 복제한다.
- 오직 하나의 브로커만이 주어진 파티션 복사본들의 리더가 될 수 있다. 그리고 Leader Brocker는 메시지를 읽고 쓰는 작업을 다루며, Follower Brocker 는 해당 데이터를 복제하여 가진다.
	- 해당 복사본을 **replica** 라고 하며, 개수가 브로커보다 많을 수 없다.

### ✅ 토픽(Topic)

- 메시지들의 특정 카테고리 또는 피드를 나타낸다.
- 생산자가 보내는 대상이며, 소비자가 받는 출처이다.
- 하나의 토픽을 여러 Consumer 가 구독할 수 있으며, 토픽에서 발행된 모든 메시지를 읽을 수 있다.

### ✅ 파티션(Partition)

- Topic 이 나눠지는 단위이다.
- key-value 구조(key 가 없으면 round-robin 방식)
- 파티션은 정렬되어 있지만, 쓰여지는 데이터는 키 값이 제공되지 않으면 파티션에 무작위로 할당된다.
- 각 Partition 속 메시지는 **unique 한 Id 값인 offset** 을 가지고 있다.

### ✅ 오프셋(Offset)

- Kafka 메시지는 Topic 내부의 Partition에 저장되며 이때 각 메시지의 고유한 일련변호
- Partiton 내에서의 위치
- Consumer 는 Offset 기준으로 메시지를 읽으며, **현재 읽은 메시지 위치**를 추적하는 단위가 오프셋

### ✅ Consumer Group 과 Consumer

Consumer 는 이벤트를 소비할 때 Polling 을 활용하여 주기적으로 소비할 이벤트가 존재하는지 확인한다.
**즉, Broker 가 소비할 주체를 정하는 게 아니라 Consumer 가 직접 결정한다.**

Consumer Group 은 해당 Topic 에 발행된 **같은 이벤트를** Consume 하는 Consumer 집단이다.
- 메시지를 어디까지 소비했는지(offset)와 메시지를 어떻게 처리할지의 로직을 정의할 수 있다.
- Partition 개수를 Consumer 보다 항상 같거나 많게 유지해야 한다.
- 소비된 메시지는 바로 삭제하지 않고, 일정기간동안 디스크에 보존한다.

| Partition | Consumer | 처리 방식               |
| --------- | -------- | ------------------- |
| 3         | 1        | 병렬X, 1개 처리          |
| 3         | 2        | 병렬 2개 처리,     1개 대기 |
| 3         | 3        | 병렬 3개 처리(이상적)       |
| 3         | 4        | 1개 스레드 낭비           |

## 핵심 설정

### `heartbeat.interval.ms`

- 컨슈머가 브로커에서 '살아있음'의 핑을 보내는 주기
- 보통 3초

### `session.timeout.ms`

- 브로커가 `hearbeat` 를 기다려주는 최대 시간
- 설정해둔 시간 내에 `heartbeat`가 오지 않으면 **다른 컨슈머에게 파티션을 할당**한다.

### `max.poll.interval.ms`

- **데이터 처리가 너무 오래 걸려서 컨슈머가 죽은 줄 아는 상황**을 막기 위한 설정
- 컨슈머가 Poll 하고 로직을 처리한 뒤, 다시 poll 할 때까지의 최대시간
- DB 작업이 무거울 때 5분 이상으로 늘려줌
___

## 📌 Kafka의 순서 보장

![](../../images/스크린샷%202026-02-02%2017.39.22.png)

1. Producer(생산자)가 선택한 Topic으로 데이터를 발행한다.

2. Kafka는 **Partition 단위로 메시지의 순서**를 보장한다.

3. 각 Partition의 메시지는 Offset을 기준으로 순차적으로 저장된다.

4. **메시지 순서를 보장**하려면 **동일한 Key를 설정하여 같은 Partition에 할당**하여 순서를 보장할 수 있다.
	- **Key 를 명시한 경우** : 같은 Key를 가진 메시지들은 항상 같은 Partiton 에 전송된다.
	- **Key를 명시하지 않은 경우** : Round-Robin 방식으로 여러 Partition에 분산시킨다.(순서보장X)

`Offset`은 **순차 증가하기** 때문에 하나의 **Partition에서 메시지는 항상 입력된 순서대로** 소비된다.
따라서 특정 유형의 메시지 순서를 보장해야 한다면 **Key를 설정하여 같은 Partition으로 전송**되도록 설정한다.

## Commit

Kafka 에서 메시지를 정상적으로 처리하였음을 알리기 위해서는 Commit 작업이 필요하다.

**Commit 속성**

- **메시지 처리 완료의 표시** : 해당 Offset 까지 정상적으로 메시지를 처리했음을 알리는 작업
- **다음 메시지 수신 가능** : 커밋된 Offset 기준으로 다음 메시지를 Conumser 에게 전달
- **Kafka 내부 토픽에 해당 Commit 저장** : `_consumer_offsets` 라는 내부 토픽에 각 Consumer Group의 Offset 상태 기록
- **중복 메시지 전송** : Commit 하지 않으면(실패 or 누락), 해당 Offset 부터 메시지를 다시 전송

### Commit 종류 (AckMode)

#### 자동 커밋

`BATCH` 
- **동작** : `poll()` 로 가져온 메시지들을 에러가 없으면 한번에 처리 
- 배치 처리 도중 에러가 발생하면 에러가 발생하지 않은 메시지들은 중복 처리될 수 있음
- 커밋 횟수가 적어서 가장 빠름

`RECORD`
- **동작** : 리스너가 메시지를 1개 처리할 때마다 즉시 커밋
- 메시지 중복 처리 최소화
- 커밋이 빈번하게 일어나므로 가장 느림, 비용 많이 듬

`COUNT`
- **동작** : 처리한 레코드 개수가 특정 숫자가 되면 커밋

`TIME`
- **동작** : 마지막 커밋 이후 일정 시간이 지나면 커밋
- 데이터 적을 때 유용

#### 수동 커밋

`MANUAL`
- **동작** : `ack.acknowledge()`를 호출하면, 해당 이벤트를 **처리 완료 마킹**만 해둠.
		그리고 배치가 끝나면 모아서 한번에 commit

`MANUAL_IMMEDIATE`
- **동작** : `ack.acknowledge()`를 호출함과 동시에 **즉시 commit**
- 실시간성이 `MANNUAL보다 강함
- 커밋 비용 많이 듬

## 비유

Kafka 를 큰 창고(데이터 저장소)라고 가정해보자.
이 창고에는 많은 **상자(Topic)** 들이 있고 각 상자는 여러 **칸(Partition)** 들로 나뉘어져 있다. 이 창고에서 데이터를 생산하는 **Producer** 가 데이터를 **상자(Topic)** 에 넣어놓고, **소비자(Consumer)** 가 필요할때 상자를 가져가서 사용한다.

이 창고를 관리하기 위해서는 **관리자**가 필요하다.
관리자는 창고 내의 상자들이 어떤 상태인지, 어디에 위치해 있는지,  어떤 소비자가 어떤 상자를 사용하는지 파악해야 한다. 이 관리자의 역할을 [[Zookeeper]] 로 비유할 수 있다.



